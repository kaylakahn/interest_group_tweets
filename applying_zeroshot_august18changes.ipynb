{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import torch # if on apple silicon, must be imported or model will fall to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Kayla/Library/CloudStorage/OneDrive-ThePennsylvaniaStateUniversity/RA_SPR_2024/data/kayla_data/')\n",
    "df = pd.read_csv('tweets_final_cleaned_july23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kayla/HuggingFaceGuidedTourForMac/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = [\"takes a position\", \"does not take a position\"]\n",
    "hypothesis_template = \"This tweet {} on a political issue\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\", device=torch.device('mps'), batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the classification. saving files every 8000 in case of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, id_col, text_col, hypothesis_template, candidate_labels):\n",
    "    texts = batch[text_col].tolist()  # Convert batch texts to a list\n",
    "    results = classifier(texts, candidate_labels=candidate_labels, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "    \n",
    "    # Extract results for each text\n",
    "    df_results = pd.DataFrame({\n",
    "        'tweet_id': batch[id_col],  # Include the tweet ID\n",
    "        'text': texts,  # Include the original text\n",
    "        'predicted_label': [result['labels'][0] for result in results],\n",
    "        'score': [result['scores'][0] for result in results]\n",
    "    })\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def predict_political(df, id_col, text_col, hypothesis_template, candidate_labels, batch_size=8000, checkpoint_dir='checkpoints_large'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "    \n",
    "    # Determine starting point based on existing checkpoint files\n",
    "    existing_files = sorted([f for f in os.listdir(checkpoint_dir) if f.startswith('batch_')])\n",
    "    start_batch = len(existing_files)\n",
    "    \n",
    "    for i in tqdm(range(start_batch, num_batches), desc=\"Processing Batches\"):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(df))\n",
    "\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "\n",
    "        # Process the batch\n",
    "        batch_results = process_batch(batch, id_col, text_col, hypothesis_template, candidate_labels)\n",
    "\n",
    "        # Save the current batch's results to a separate file\n",
    "        batch_filename = os.path.join(checkpoint_dir, f'batch_{i}.csv')\n",
    "        batch_results.to_csv(batch_filename, index=False)\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    # Concatenate all batch files into a single file at the end\n",
    "    batch_files = sorted([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('batch_')])\n",
    "    final_result_df = pd.concat((pd.read_csv(f) for f in batch_files), ignore_index=True)\n",
    "\n",
    "    # Save the final results to a CSV file\n",
    "    final_output_path = 'final_classified_tweets.csv'\n",
    "    final_result_df.to_csv(final_output_path, index=False)\n",
    "    \n",
    "    return final_result_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 144/144 [6:00:25<00:00, 150.18s/it]  \n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "candidate_labels = ['takes a position', 'does not take a position']\n",
    "hypothesis_template = 'This tweet {} on a political issue'\n",
    "checkpoint_dir = '/kayla_data/checkpoints/checkpoints_large_aug'\n",
    "final_results = predict_political(df, id_col='tweet_id', text_col=text_col, hypothesis_template=hypothesis_template,candidate_labels=candidate_labels, batch_size=5000, checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant df save just in case\n",
    "final_results.to_csv('deblarge_classified_tweets_aug.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/kayla_data/final_classified_tweets_aug19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431606"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc[df['predicted_label'] == 'takes a position'].to_csv('classified_deblarge_positives.csv')\n",
    "len(df.loc[df['predicted_label'] == 'takes a position'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HuggingFaceGuidedTourForMac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
